from snakemake.utils import min_version

##### set minimum snakemake version #####
min_version("6.4.1")


##### setup report #####
configfile: "config/config.yml"

# import os
# import csv
# import pandas as pd

# METADATA = (
#     pd.read_csv(config["samples"], sep="\t", dtype={"sample_name": str})
#     .set_index("sample_name", drop=False)
#     .sort_index()
# )

# SAMPLES = METADATA["sample_name"]


# OUTDIR="data/reads" 
# TEMPDIR="data/temp"

# if not os.path.exists(OUTDIR):
#    os.makedirs(OUTDIR)

# if not os.path.exists(TEMPDIR):
#    os.makedirs(TEMPDIR)


report: "report/workflow.rst"


##### setup singularity #####


# this container defines the underlying OS for each job when using the workflow
# with --use-conda --use-singularity
# container: "docker://continuumio/miniconda3"


##### load rules #####


include: "rules/common.smk"
include: "rules/import_metadata.smk"
include: "rules/fasterq_dump_fastq.smk"
include: "rules/pigz_compress_fastq.smk"
include: "rules/extract_sra_accs.smk"
# include: "rules/resize_fastq_files.smk"

include: "rules/rmd_report.smk"


# Master rule for controlling workflow.
rule all:
    input:
        "index.html",
        # "config/pe_samples.tsv",
        # "config/pe_units.tsv",
        # "resources/metadata/pe_metadata.tsv",
        # "config/se_samples.tsv",
        # "config/se_units.tsv",
        # "resources/metadata/se_metadata.tsv",

        # "config/sra_accs.txt",

        expand("{outdir}/{sample}_{sraNum}.fastq", outdir=OUTDIR, sample=SAMPLES, sraNum=config["sraNum"]),
        expand("{outdir}/{sample}_{sraNum}.fastq.gz", outdir=OUTDIR, sample=SAMPLES, sraNum=config["sraNum"]),




