from snakemake.utils import min_version

min_version("6.10.0")

# Configuration file containing all user-specified settings
configfile: "config/config.yaml"


import os
import csv
import pandas as pd

METADATA=pd.read_csv('data/metadata/metadata.csv').loc[0:3]
ACCESSIONS=METADATA['run'].tolist()

OUTDIR="data/reads" 
TEMPDIR="data/temp"

if not os.path.exists(OUTDIR):
   os.makedirs(OUTDIR)

if not os.path.exists(TEMPDIR):
   os.makedirs(TEMPDIR)

# Master rule for controlling workflow.
rule all:
    input:
        expand("data/reads/{accession}_{sraNum}.fastq", accession=ACCESSIONS, sraNum=config["sraNum"]),
        expand("data/subset/{accession}_{sraNum}.fastq", accession=ACCESSIONS, sraNum=config["sraNum"]),
        "index.html",


# Import metadata
rule get_sra_metadata:
    output:
        metadata=METADATA
    shell:
        """
        echo "Getting metadata"
        """

rule extract_sra_accession: 
    input:
        metadata=METADATA
    output:
        acc=ACCESSIONS
    shell:
        """
        echo "Getting SRA accessions"
        """


# Dowload the SRA RUN reads
rule fasterq_dump_sra_reads: 
    input:
        acc=ACCESSIONS,
    output:
        fastq=expand("data/reads/{accession}_{sraNum}.fastq", accession=ACCESSIONS, sraNum=config["sraNum"]),
    params:
        outfolder=OUTDIR,
        temp=TEMPDIR,
    threads: 1
    shell:
        """
        fasterq-dump \
        --split-3 \
        --force \
        --outdir {params.outfolder} \
        --temp {params.temp} \
        --threads {threads}
        """

# Subset a test data
rule resize_for_testing:
    input:
        fastq=rules.fasterq_dump_sra_reads.output.fastq,
    output:
        expand("data/subset/{accession}_{sraNum}.fastq", accession=ACCESSIONS, sraNum=config["sraNum"]),
    threads: 1
    shell:
        """
        bash workflow/scripts/resize_fastq.sh
        """


# Get dot rule graphs
rule dot_rules_graph:
	output:
		"dags/rulegraph.svg",
		"dags/rulegraph.png",
	shell:
		"bash workflow/scripts/rules_dag.sh"


# Get project tree
rule project_tree:
    output:
        tree="results/project_tree.txt"
    shell:
        """
        bash workflow/scripts/tree.sh
        """

# Get smk static report
rule static_snakemake_report:
    output:
        smkhtml="report.html",
        html2png="images/smkreport/screenshot.png"
    shell:
        """
        bash workflow/scripts/smk_html_report.sh
        """

rule deploy_to_github_pages:
    input:
        script="workflow/scripts/render.R",
        rmd="index.Rmd",
        tree="results/project_tree.txt",
        html2png=rules.static_snakemake_report.output.html2png,
        rules="dags/rulegraph.svg",
    output:
        doc="index.html",
    shell:
        """
        R -e "library(rmarkdown); render('{input.rmd}')"
        """



# rule seqkit_simple_stats:
#     input:
#         script="workflow/scripts/seqkit_stat_1.sh",
#         rawreads=expand("data/reads/{accession}_{sraNum}.fastq", accession=ACCESSIONS, sraNum=config["sraNum"]),
#     output:
#         seqkit1="results/stats1/seqkit_stats.txt",
#     threads: 1
#     shell:
#       "bash {input.script}"


# rule mothur_mapping_file:
#     input:
#         stats1="results/stats1/seqkit_stats.txt"
#     output:
#         files="data/metadata/mothur_mapping_file.tsv",
#     threads: 1
#     script:
#       "scripts/mothur_mapping_file.R"


# rule mothur_design_file:
#     input:
#         files="data/metadata/mothur_mapping_file.tsv",
#     output:
#         files="data/metadata/mothur_design_file.tsv",
#     threads: 1
#     script:
#       "scripts/mothur_design_file.R"

# # Downloading and formatting SILVA and RDP reference databases. The v4 region is extracted from 
# # SILVA database for use as reference alignment.
# rule mothur_references:
# 	input:
# 		script="workflow/scripts/mothurReferences.sh"
# 	output:
# 		silvaV4="data/mothur/references/silva.v4.align",
# 		rdpFasta="data/mothur/references/trainset16_022016.pds.fasta",
# 		rdpTax="data/mothur/references/trainset16_022016.pds.tax"
# 	conda:
# 		"envs/mothur.yaml"
# 	shell:
# 		"bash {input.script}"


# # Downloading the Zymo mock sequence files and extracting v4 region for error estimation.
# rule mothur_zymo_mock:
# 	input:
# 		script="workflow/scripts/mothurMock.sh",
# 		silvaV4="data/mothur/references/silva.v4.align",
# 	output:
# 		mockV4="data/mothur/references/zymo.mock.16S.v4.fasta"
# 	conda:
# 		"envs/mothur.yaml"
# 	shell:
# 		"bash {input.script}"


# rule gather_bioinfo_resources:
#     shell:
#         """
#         bash workflow/scripts/get_bioinfo_resources.sh
#         """



